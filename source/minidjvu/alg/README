This is the collection of algorithms that together do the job.
The code is distributed very unevenly, from 1K in clean/ to 60K in jb2/.
Here is the quick list of them;
    they are listed in the order they are naturally used to compress.

    smooth   - remove pixels that look bad
    split    - split a bitmap into pieces (result is a mdjvu_image_t object)
    clean    - remove small marks
    nosubst  - determining what pieces are letters and what are not
    blitsort - sorting letters in approximate reading order
    patterns - compare letters (to find if one may be substituted for another)
    classify - classify letters; uses the pattern matcher (`patterns')
    average  - producing an "average" bitmap to use as a representative
    delegate - pick up a representative from each class of equivalent letters
    adjust_y - adjust substitution positions (otherwise the text looks bumpy)
    erosion  - determine what pixels may be eroded
